{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OAidmUlVxHJ2",
        "outputId": "eab6d215-3dde-4f47-9317-f2ee37233ff5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lCe8m6pu6-y",
        "outputId": "7aae2ada-d2fb-42b1-dd00-576ce89448e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Corpus:\n",
            " [['deep', 'learning', 'is', 'core', 'subject', 'of', 'artificial', 'intelligence'], ['machine', 'learning', 'is', 'subbranch', 'of', 'deep', 'learning'], ['convolutional', 'neural', 'network', 'cnn', 'is', 'basic', 'deep', 'neural', 'network', 'in', 'deep', 'learning'], ['alex', 'and', 'visual', 'geometry', 'group', 'vgg', 'neural', 'networks', 'are', 'pre', 'trained', 'deep', 'neural', 'networks'], ['deep', 'residual', 'network', 'is', 'used', 'in', 'image', 'recognition']]\n",
            "\n",
            "Vocab:\n",
            " {'in', 'image', 'cnn', 'machine', 'is', 'basic', 'recognition', 'residual', 'networks', 'alex', 'geometry', 'vgg', 'are', 'intelligence', 'and', 'trained', 'used', 'learning', 'convolutional', 'visual', 'neural', 'deep', 'network', 'core', 'pre', 'of', 'subject', 'group', 'artificial', 'subbranch'}\n",
            "\n",
            "Vocab Size: 30\n",
            "\n",
            " Epoch [10/100], Loss: 0.0263\n",
            "\n",
            " Epoch [20/100], Loss: 0.0077\n",
            "\n",
            " Epoch [30/100], Loss: 0.0037\n",
            "\n",
            " Epoch [40/100], Loss: 0.0022\n",
            "\n",
            " Epoch [50/100], Loss: 0.0014\n",
            "\n",
            " Epoch [60/100], Loss: 0.0009\n",
            "\n",
            " Epoch [70/100], Loss: 0.0007\n",
            "\n",
            " Epoch [80/100], Loss: 0.0005\n",
            "\n",
            " Epoch [90/100], Loss: 0.0003\n",
            "\n",
            " Epoch [100/100], Loss: 0.0003\n",
            "\n",
            "Word Embeddings:\n",
            "deep: [-0.9155559  -0.7570975   0.50999266 -1.0051765   0.29884893 -0.52109253\n",
            " -0.2635769  -0.16746044] ...\n",
            "learning: [ 1.7373567  -0.4527855  -0.6010431   0.90069526 -0.78414816  0.05806758\n",
            "  0.06912331  0.41685292] ...\n",
            "intelligence: [ 0.8098865   1.354655    1.0201198  -0.612854   -0.70353574  1.0001811\n",
            "  0.48910347  0.6635138 ] ...\n",
            "network: [-0.16853052 -0.9309673  -0.55585366 -0.25510663  0.2223159  -0.10497037\n",
            " -0.78699744  0.52980065] ...\n"
          ]
        }
      ],
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "corpus = [\n",
        "    \"Deep learning is a core subject of artificial intelligence\",\n",
        "    \"Machine learning is a subbranch of deep learning\",\n",
        "    \"Convolutional Neural Network (CNN) is a basic deep neural network in deep learning\",\n",
        "    \"Alex and Visual Geometry Group (VGG) neural networks are pre trained deep neural networks\",\n",
        "    \"Deep residual network is used in image recognition\"\n",
        "]\n",
        "\n",
        "tokenized_corpus = [simple_preprocess(line) for line in corpus]\n",
        "print(\"Tokenized Corpus:\\n\", tokenized_corpus)\n",
        "\n",
        "words = [word for sentence in tokenized_corpus for word in sentence]\n",
        "vocab = set(words)\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "vocab_size = len(vocab)\n",
        "print(\"\\nVocab:\\n\", vocab)\n",
        "print(\"\\nVocab Size:\", vocab_size)\n",
        "\n",
        "class WordEmbeddingModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(WordEmbeddingModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs)\n",
        "        output = self.linear(embeds)\n",
        "        return output\n",
        "\n",
        "vector_size = 300\n",
        "model = WordEmbeddingModel(vocab_size, vector_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "training_data = []\n",
        "for sentence in tokenized_corpus:\n",
        "    for i, target_word in enumerate(sentence):\n",
        "        target_idx = word2idx[target_word]\n",
        "        context_idx = word2idx[target_word]\n",
        "        training_data.append((context_idx, target_idx))\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for context_idx, target_idx in training_data:\n",
        "        context_tensor = torch.LongTensor([context_idx])\n",
        "        target_tensor = torch.LongTensor([target_idx])\n",
        "        outputs = model(context_tensor)\n",
        "        loss = criterion(outputs, target_tensor)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'\\n Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(training_data):.4f}')\n",
        "\n",
        "word_embeddings = model.embeddings.weight.data\n",
        "print(\"\\nWord Embeddings:\")\n",
        "for word in [\"deep\", \"learning\", \"intelligence\", \"network\"]:\n",
        "    if word in word2idx:\n",
        "        print(f\"{word}: {word_embeddings[word2idx[word]].numpy()[:8]} ...\")"
      ]
    }
  ]
}